{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Answer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "772fbf5e-4795-4556-9dd6-9d31253297fa"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a55181bd-4755-49a1-a837-f6d094a198e8"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-09 16:22:56--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  34.3MB/s    in 2.4s    \n",
            "\n",
            "2020-01-09 16:22:59 (34.3 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "c7ea1306-5d90-4b2c-f453-d9a81ddc81b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c603a26-2af3-4982-fe20-6e18ecf11572"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "a69749b8-9229-488e-d9aa-08bf4ee75104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-09 16:25:19--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   218MB/s    in 0.7s    \n",
            "\n",
            "2020-01-09 16:25:19 (218 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-01-09 16:25:21--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-01-09 16:25:21 (135 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "ece8b95f-e465-4ff7-8976-f70c41c49ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "89121e71-6f47-495a-d2ed-38949b351f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "a821d0f6-fc15-4f49-f1ef-0b70dfb2e278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 100,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 0.0698 - acc: 0.9802\n",
            "100/100 - 34s - loss: 0.0870 - acc: 0.9762 - val_loss: 0.0698 - val_acc: 0.9802\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.1157 - acc: 0.9762\n",
            "100/100 - 33s - loss: 0.0264 - acc: 0.9909 - val_loss: 0.1157 - val_acc: 0.9762\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.1422 - acc: 0.9691\n",
            "100/100 - 32s - loss: 0.0631 - acc: 0.9819 - val_loss: 0.1422 - val_acc: 0.9691\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.0449 - acc: 0.9888\n",
            "100/100 - 32s - loss: 0.0290 - acc: 0.9894 - val_loss: 0.0449 - val_acc: 0.9888\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.0473 - acc: 0.9888\n",
            "100/100 - 32s - loss: 0.0411 - acc: 0.9857 - val_loss: 0.0473 - val_acc: 0.9888\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.1324 - acc: 0.9731\n",
            "100/100 - 32s - loss: 0.0271 - acc: 0.9883 - val_loss: 0.1324 - val_acc: 0.9731\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.0540 - acc: 0.9919\n",
            "100/100 - 31s - loss: 0.0226 - acc: 0.9935 - val_loss: 0.0540 - val_acc: 0.9919\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.4814 - acc: 0.9569\n",
            "100/100 - 32s - loss: 0.0439 - acc: 0.9893 - val_loss: 0.4814 - val_acc: 0.9569\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2856 - acc: 0.9640\n",
            "100/100 - 32s - loss: 0.0264 - acc: 0.9930 - val_loss: 0.2856 - val_acc: 0.9640\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.1246 - acc: 0.9731\n",
            "100/100 - 31s - loss: 0.0142 - acc: 0.9965 - val_loss: 0.1246 - val_acc: 0.9731\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2442 - acc: 0.9686\n",
            "100/100 - 31s - loss: 0.0151 - acc: 0.9969 - val_loss: 0.2442 - val_acc: 0.9686\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.7772 - acc: 0.9412\n",
            "100/100 - 32s - loss: 0.0254 - acc: 0.9909 - val_loss: 0.7772 - val_acc: 0.9412\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2708 - acc: 0.9686\n",
            "100/100 - 31s - loss: 0.0219 - acc: 0.9949 - val_loss: 0.2708 - val_acc: 0.9686\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 0.6128 - acc: 0.9437\n",
            "100/100 - 31s - loss: 0.0258 - acc: 0.9935 - val_loss: 0.6128 - val_acc: 0.9437\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.5940 - acc: 0.9462\n",
            "100/100 - 33s - loss: 0.0070 - acc: 0.9969 - val_loss: 0.5940 - val_acc: 0.9462\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.4310 - acc: 0.9604\n",
            "100/100 - 32s - loss: 0.0143 - acc: 0.9939 - val_loss: 0.4310 - val_acc: 0.9604\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.5171 - acc: 0.9599\n",
            "100/100 - 32s - loss: 0.0067 - acc: 0.9965 - val_loss: 0.5171 - val_acc: 0.9599\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.3964 - acc: 0.9610\n",
            "100/100 - 31s - loss: 0.0062 - acc: 0.9985 - val_loss: 0.3964 - val_acc: 0.9610\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.6976 - acc: 0.9473\n",
            "100/100 - 31s - loss: 0.0144 - acc: 0.9954 - val_loss: 0.6976 - val_acc: 0.9473\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.3349 - acc: 0.9681\n",
            "100/100 - 32s - loss: 0.0209 - acc: 0.9945 - val_loss: 0.3349 - val_acc: 0.9681\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.4228 - acc: 0.9615\n",
            "100/100 - 32s - loss: 0.0122 - acc: 0.9959 - val_loss: 0.4228 - val_acc: 0.9615\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2071 - acc: 0.9802\n",
            "100/100 - 32s - loss: 0.0240 - acc: 0.9940 - val_loss: 0.2071 - val_acc: 0.9802\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2167 - acc: 0.9802\n",
            "100/100 - 32s - loss: 0.0373 - acc: 0.9959 - val_loss: 0.2167 - val_acc: 0.9802\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.3875 - acc: 0.9579\n",
            "100/100 - 31s - loss: 0.0283 - acc: 0.9934 - val_loss: 0.3875 - val_acc: 0.9579\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.3063 - acc: 0.9762\n",
            "100/100 - 31s - loss: 0.0210 - acc: 0.9944 - val_loss: 0.3063 - val_acc: 0.9762\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.6010 - acc: 0.9478\n",
            "100/100 - 31s - loss: 0.0170 - acc: 0.9959 - val_loss: 0.6010 - val_acc: 0.9478\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 0.1971 - acc: 0.9812\n",
            "100/100 - 31s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.1971 - val_acc: 0.9812\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2695 - acc: 0.9762\n",
            "100/100 - 33s - loss: 0.0125 - acc: 0.9975 - val_loss: 0.2695 - val_acc: 0.9762\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.7749 - acc: 0.9493\n",
            "100/100 - 33s - loss: 0.0106 - acc: 0.9970 - val_loss: 0.7749 - val_acc: 0.9493\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.3344 - acc: 0.9610\n",
            "100/100 - 32s - loss: 0.0222 - acc: 0.9944 - val_loss: 0.3344 - val_acc: 0.9610\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.1072 - acc: 0.9919\n",
            "100/100 - 31s - loss: 0.0057 - acc: 0.9985 - val_loss: 0.1072 - val_acc: 0.9919\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.4122 - acc: 0.9604\n",
            "100/100 - 32s - loss: 0.0220 - acc: 0.9954 - val_loss: 0.4122 - val_acc: 0.9604\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.3685 - acc: 0.9726\n",
            "100/100 - 32s - loss: 0.0127 - acc: 0.9965 - val_loss: 0.3685 - val_acc: 0.9726\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.4718 - acc: 0.9569\n",
            "100/100 - 31s - loss: 0.0367 - acc: 0.9939 - val_loss: 0.4718 - val_acc: 0.9569\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2916 - acc: 0.9731\n",
            "100/100 - 32s - loss: 0.0118 - acc: 0.9970 - val_loss: 0.2916 - val_acc: 0.9731\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.6003 - acc: 0.9483\n",
            "100/100 - 31s - loss: 0.0139 - acc: 0.9964 - val_loss: 0.6003 - val_acc: 0.9483\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.2241 - acc: 0.9767\n",
            "100/100 - 31s - loss: 0.0174 - acc: 0.9965 - val_loss: 0.2241 - val_acc: 0.9767\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.7996 - acc: 0.9498\n",
            "100/100 - 32s - loss: 0.0268 - acc: 0.9939 - val_loss: 0.7996 - val_acc: 0.9498\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.6873 - acc: 0.9493\n",
            "100/100 - 31s - loss: 0.0053 - acc: 0.9980 - val_loss: 0.6873 - val_acc: 0.9493\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 0.5281 - acc: 0.9599\n",
            "100/100 - 31s - loss: 0.0138 - acc: 0.9975 - val_loss: 0.5281 - val_acc: 0.9599\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.5936 - acc: 0.9574\n",
            "100/100 - 33s - loss: 0.0133 - acc: 0.9980 - val_loss: 0.5936 - val_acc: 0.9574\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.4771 - acc: 0.9650\n",
            "100/100 - 32s - loss: 0.0215 - acc: 0.9965 - val_loss: 0.4771 - val_acc: 0.9650\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.8072 - acc: 0.9462\n",
            "100/100 - 32s - loss: 0.0127 - acc: 0.9965 - val_loss: 0.8072 - val_acc: 0.9462\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.4112 - acc: 0.9366\n",
            "100/100 - 32s - loss: 0.0059 - acc: 0.9975 - val_loss: 1.4112 - val_acc: 0.9366\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.9637 - acc: 0.9457\n",
            "100/100 - 31s - loss: 0.0100 - acc: 0.9964 - val_loss: 0.9637 - val_acc: 0.9457\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.0970 - acc: 0.9452\n",
            "100/100 - 31s - loss: 0.0065 - acc: 0.9970 - val_loss: 1.0970 - val_acc: 0.9452\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.0007 - acc: 0.9447\n",
            "100/100 - 32s - loss: 0.0045 - acc: 0.9990 - val_loss: 1.0007 - val_acc: 0.9447\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.1635 - acc: 0.9457\n",
            "100/100 - 31s - loss: 0.0080 - acc: 0.9969 - val_loss: 1.1635 - val_acc: 0.9457\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.7930 - acc: 0.9498\n",
            "100/100 - 32s - loss: 0.0109 - acc: 0.9975 - val_loss: 0.7930 - val_acc: 0.9498\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.0007 - acc: 0.9407\n",
            "100/100 - 31s - loss: 0.0286 - acc: 0.9944 - val_loss: 1.0007 - val_acc: 0.9407\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.9809 - acc: 0.9442\n",
            "100/100 - 31s - loss: 0.0102 - acc: 0.9975 - val_loss: 0.9809 - val_acc: 0.9442\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.9374 - acc: 0.9462\n",
            "100/100 - 32s - loss: 0.0082 - acc: 0.9975 - val_loss: 0.9374 - val_acc: 0.9462\n",
            "Epoch 53/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 0.9502 - acc: 0.9533\n",
            "100/100 - 30s - loss: 0.0100 - acc: 0.9975 - val_loss: 0.9502 - val_acc: 0.9533\n",
            "Epoch 54/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.8547 - acc: 0.9533\n",
            "100/100 - 33s - loss: 0.0125 - acc: 0.9975 - val_loss: 0.8547 - val_acc: 0.9533\n",
            "Epoch 55/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.5018 - acc: 0.9716\n",
            "100/100 - 33s - loss: 0.0182 - acc: 0.9975 - val_loss: 0.5018 - val_acc: 0.9716\n",
            "Epoch 56/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.8876 - acc: 0.9503\n",
            "100/100 - 32s - loss: 0.0072 - acc: 0.9985 - val_loss: 0.8876 - val_acc: 0.9503\n",
            "Epoch 57/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.4576 - acc: 0.9432\n",
            "100/100 - 31s - loss: 0.0053 - acc: 0.9990 - val_loss: 1.4576 - val_acc: 0.9432\n",
            "Epoch 58/100\n",
            "Epoch 1/100\n",
            "100/100 - 10s - loss: 0.8847 - acc: 0.9422\n",
            "100/100 - 32s - loss: 0.0066 - acc: 0.9985 - val_loss: 0.8847 - val_acc: 0.9422\n",
            "Epoch 59/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.4187 - acc: 0.9371\n",
            "100/100 - 32s - loss: 0.0112 - acc: 0.9975 - val_loss: 1.4187 - val_acc: 0.9371\n",
            "Epoch 60/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 2.0296 - acc: 0.9255\n",
            "100/100 - 31s - loss: 0.0141 - acc: 0.9990 - val_loss: 2.0296 - val_acc: 0.9255\n",
            "Epoch 61/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.1211 - acc: 0.9407\n",
            "100/100 - 32s - loss: 0.0042 - acc: 0.9985 - val_loss: 1.1211 - val_acc: 0.9407\n",
            "Epoch 62/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.6997 - acc: 0.9305\n",
            "100/100 - 31s - loss: 0.0042 - acc: 0.9980 - val_loss: 1.6997 - val_acc: 0.9305\n",
            "Epoch 63/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.4075 - acc: 0.9376\n",
            "100/100 - 32s - loss: 0.0105 - acc: 0.9975 - val_loss: 1.4075 - val_acc: 0.9376\n",
            "Epoch 64/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.9446 - acc: 0.9285\n",
            "100/100 - 32s - loss: 0.0185 - acc: 0.9965 - val_loss: 1.9446 - val_acc: 0.9285\n",
            "Epoch 65/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.9558 - acc: 0.9488\n",
            "100/100 - 32s - loss: 0.0154 - acc: 0.9959 - val_loss: 0.9558 - val_acc: 0.9488\n",
            "Epoch 66/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 2.1387 - acc: 0.9285\n",
            "100/100 - 31s - loss: 0.0103 - acc: 0.9970 - val_loss: 2.1387 - val_acc: 0.9285\n",
            "Epoch 67/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.3414 - acc: 0.9412\n",
            "100/100 - 33s - loss: 0.0084 - acc: 0.9980 - val_loss: 1.3414 - val_acc: 0.9412\n",
            "Epoch 68/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.9148 - acc: 0.9518\n",
            "100/100 - 32s - loss: 0.0165 - acc: 0.9965 - val_loss: 0.9148 - val_acc: 0.9518\n",
            "Epoch 69/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 2.4567 - acc: 0.9178\n",
            "100/100 - 32s - loss: 0.0103 - acc: 0.9965 - val_loss: 2.4567 - val_acc: 0.9178\n",
            "Epoch 70/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.5099 - acc: 0.9371\n",
            "100/100 - 32s - loss: 0.0144 - acc: 0.9954 - val_loss: 1.5099 - val_acc: 0.9371\n",
            "Epoch 71/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.4250 - acc: 0.9381\n",
            "100/100 - 31s - loss: 0.0108 - acc: 0.9980 - val_loss: 1.4250 - val_acc: 0.9381\n",
            "Epoch 72/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.5783 - acc: 0.9381\n",
            "100/100 - 32s - loss: 0.0120 - acc: 0.9980 - val_loss: 1.5783 - val_acc: 0.9381\n",
            "Epoch 73/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.3568 - acc: 0.9407\n",
            "100/100 - 31s - loss: 0.0149 - acc: 0.9959 - val_loss: 1.3568 - val_acc: 0.9407\n",
            "Epoch 74/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.2005 - acc: 0.9417\n",
            "100/100 - 32s - loss: 0.0119 - acc: 0.9965 - val_loss: 1.2005 - val_acc: 0.9417\n",
            "Epoch 75/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.5668 - acc: 0.9645\n",
            "100/100 - 32s - loss: 0.0401 - acc: 0.9944 - val_loss: 0.5668 - val_acc: 0.9645\n",
            "Epoch 76/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.0794 - acc: 0.9447\n",
            "100/100 - 31s - loss: 0.0114 - acc: 0.9975 - val_loss: 1.0794 - val_acc: 0.9447\n",
            "Epoch 77/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.7743 - acc: 0.9579\n",
            "100/100 - 31s - loss: 0.0347 - acc: 0.9954 - val_loss: 0.7743 - val_acc: 0.9579\n",
            "Epoch 78/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 0.7829 - acc: 0.9579\n",
            "100/100 - 32s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.7829 - val_acc: 0.9579\n",
            "Epoch 79/100\n",
            "Epoch 1/100\n",
            "100/100 - 8s - loss: 1.4194 - acc: 0.9371\n",
            "100/100 - 31s - loss: 0.0091 - acc: 0.9985 - val_loss: 1.4194 - val_acc: 0.9371\n",
            "Epoch 80/100\n",
            "Epoch 1/100\n",
            "100/100 - 9s - loss: 1.0710 - acc: 0.9513\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 33s - loss: 9.7961e-04 - acc: 0.9995 - val_loss: 1.0710 - val_acc: 0.9513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "a7aa5724-2992-4590-ca99-efcb972cce95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}