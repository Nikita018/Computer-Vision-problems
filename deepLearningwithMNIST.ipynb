{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepLearningwithMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjIFoBRBbbnj",
        "colab_type": "code",
        "outputId": "edf84fc0-0bdb-41a3-f851-e74ca534bcc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILapYDwCcJMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist=keras.datasets.fashion_mnist\n",
        "(train_images,train_labels), (test_images,test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs4xdiGt0Cvu",
        "colab_type": "code",
        "outputId": "540ca3da-567e-4ce9-cea9-441c6aa8cd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[1142])\n",
        "print(train_labels[1142])\n",
        "print(train_images[1142])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "[[  0   0   0   0   0   0   0   0   1   0   0   0 159 165 165 184 162   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   5   0   0   0   4 206 249 170 171 177 255 177\n",
            "    0   0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0  29 181 218 222 216 221 204 220 206 226\n",
            "  253 146   8   0   0   1   0   0   0   0]\n",
            " [  0   0   0   1   1   0   0 135 221 224 210 207 220 208 199 210 208 210\n",
            "  210 228 214 116   0   0   1   0   0   0]\n",
            " [  0   0   0   1   0   0 152 238 208 207 213 208 209 219 216 222 215 211\n",
            "  211 206 210 236 128   0   0   0   0   0]\n",
            " [  0   0   0   2   0  52 224 212 209 210 205 208 208 208 207 206 208 207\n",
            "  210 212 210 209 218  25   0   0   0   0]\n",
            " [  0   0   0   0   0 202 221 215 206 210 206 210 208 208 209 209 210 208\n",
            "  210 210 210 208 222 188   0   0   0   0]\n",
            " [  0   0   0   0  55 221 206 223 202 208 210 208 206 210 207 207 207 206\n",
            "  209 209 209 211 207 220  34   0   0   0]\n",
            " [  0   0   0   0 180 218 208 220 205 210 208 210 205 206 204 205 209 205\n",
            "  207 208 209 210 207 224 157   0   0   0]\n",
            " [  0   0   0   4 210 206 210 218 204 209 207 210 205 205 205 205 209 205\n",
            "  206 207 207 206 210 210 207   0   0   0]\n",
            " [  0   0   0 167 222 200 210 218 203 209 206 209 204 205 207 205 207 203\n",
            "  204 205 207 205 208 202 222 151   0   0]\n",
            " [  0   0   0  86 205 219 206 213 205 207 205 209 203 206 205 204 206 201\n",
            "  204 205 206 204 204 220 203  79   0   0]\n",
            " [  0   0   0   0   0 183 228 218 201 207 206 210 200 206 197 204 206 199\n",
            "  205 206 203 205 253 180   1   0   0   0]\n",
            " [  0   0   0   0   0   0  63 224 207 204 207 209 201 203 205 205 207 201\n",
            "  203 203 207 216  52   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 197 212 201 204 208 199 204 204 205 205 200\n",
            "  203 199 213 185   0   0   2   0   0   0]\n",
            " [  0   0   0   0   0   0   0 212 210 201 206 207 199 205 200 203 205 196\n",
            "  204 199 213 192   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0 212 210 200 204 208 203 202 203 204 204 196\n",
            "  203 201 212 190   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0 213 210 199 203 208 202 202 206 208 200 198\n",
            "  202 201 211 192   0   0   1   0   0   0]\n",
            " [  0   0   0   0   1   0   0 213 210 198 204 208 202 203 196 205 202 197\n",
            "  200 200 211 192   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0 215 208 197 204 208 204 202 199 206 202 197\n",
            "  201 201 210 192   0   0   0   0   0   0]\n",
            " [  0   0   0   0   2   0   0 216 207 199 204 209 205 200 204 206 198 197\n",
            "  203 201 208 196   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0 217 208 200 205 209 204 200 205 206 203 196\n",
            "  202 201 208 204   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0 217 209 200 206 209 203 200 203 204 202 195\n",
            "  202 201 207 207   0   0   1   0   0   0]\n",
            " [  0   0   0   0   1   0   0 183 209 202 205 210 201 199 204 205 204 193\n",
            "  202 202 207 179   0   0   1   0   0   0]\n",
            " [  0   0   0   0   2   0   0 190 204 203 206 208 198 203 208 206 201 195\n",
            "  199 199 201 188   0   0   2   0   0   0]\n",
            " [  0   0   0   0   2   0   0 187 224 210 203 206 195 195 204 199 193 193\n",
            "  201 214 218 174   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   1  88 196 251 252 229 218 235 231 228 240\n",
            "  233 158  76   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  20  94 132 144 151 148 123  95\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Nx5yy-R9gP",
        "colab_type": "code",
        "outputId": "bdf2643b-fa67-4d33-ab65-3410f979a9d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBs2QJeT0vp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images  = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrSjKQEVaUOh",
        "colab_type": "code",
        "outputId": "ea79267d-c9e7-4a56-c60e-2cb9a67f45bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Flatten(input_shape=(28,28)),\n",
        "      keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5gNuo0L5Wsj",
        "colab_type": "code",
        "outputId": "4fa345aa-0373-44e7-89eb-95e20914abdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images,train_labels,epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.4940 - acc: 0.8262\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.3735 - acc: 0.8646\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3337 - acc: 0.8784\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3109 - acc: 0.8852\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2949 - acc: 0.8906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f579bf077f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRBy0sPV521E",
        "colab_type": "code",
        "outputId": "a1111baf-ea47-4bcb-faee-d1524407fbe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 36us/sample - loss: 0.3464 - acc: 0.8766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.346365251660347, 0.8766]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaEhjig7_uQ6",
        "colab_type": "code",
        "outputId": "c69c6d07-06b4-466e-e388-a0ce0efab82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4761 - acc: 0.8300\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3569 - acc: 0.8699\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3236 - acc: 0.8806\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.2976 - acc: 0.8899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.2793 - acc: 0.8964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6b94eefd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMjvh3zlBDmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolution and Pooling layers for classification of Fashion MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLrAvitZP1e2",
        "colab_type": "code",
        "outputId": "816dd27c-528e-458b-a1dc-6fb0e5509e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "fashion_mnist=keras.datasets.fashion_mnist\n",
        "(train_images,train_labels), (test_images,test_labels) = fashion_mnist.load_data()\n",
        "train_images = train_images.reshape(60000,28,28,1)\n",
        "train_images = train_labels/255.0\n",
        "test_images = test_images.reshape(10000,28,28,1)\n",
        "test_images = test_labels/255.0\n",
        "model = keras.Sequential([\n",
        "      keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "      keras.layers.MaxPooling2D(2,2),\n",
        "      keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "      keras.layers.MaxPooling2D(2,2),\n",
        "      keras.layers.Flatten(input_shape=(28,28)),\n",
        "      keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.summary\n",
        "model.fit(train_images,train_labels,epochs=5)\n",
        "test_loss = model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1003ccddafc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    561\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_6_input to have 4 dimensions, but got array with shape (60000, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBwYg6sMR1Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}